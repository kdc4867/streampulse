# 페이타랩 그로스 데이터 엔지니어 지원 - 사전 질문 답변

## Q. 문제를 정의하고 실험을 설계해 개선한 경험

### 📌 프로젝트 배경
**StreamPulse**: 스트리밍 플랫폼(SOOP/CHZZK)의 라이브 트래픽을 실시간 모니터링하고, 급등 신호를 감지해 AI로 원인을 분석하는 시스템을 개발했습니다.

---

## 1️⃣ 문제 정의

### 발견한 문제점

**문제 1: 급등 감지 정확도 부족**
- 초기 시스템은 단순 임계값(1.5배 증가)만 사용
- **결과**: 
  - False Positive: 평소 시청자가 적은 카테고리에서 작은 변동도 급등으로 감지 (일일 50+ 건)
  - False Negative: 주요 카테고리의 실제 급등을 놓침 (주간 3-5건)
  - 사용자 피로도 증가 및 신뢰도 하락

**문제 2: AI 분석 비용 과다**
- 동일한 이벤트가 반복 분석됨 (같은 스트리머, 같은 시간대)
- OpenAI API 호출 비용: 일일 $15-20 (월 $450-600)
- **원인**: 캐싱 시스템 부재, 중복 분석 방지 로직 없음

**문제 3: 처리 지연**
- 이벤트 발생 후 분석 완료까지 평균 5-10분
- 실시간 대응이 필요한 급등 이벤트의 가치 저하

---

## 2️⃣ 실험 설계

### 가설 설정

**가설 1**: 다중 베이스라인 전략과 동적 임계값으로 정확도 개선 가능
- 단기(60분 중앙값) + 장기(7일/24시간 평균) 비교
- 카테고리 규모에 따른 차등 임계값 적용

**가설 2**: Redis 캐싱으로 중복 분석 비용 70% 이상 절감 가능
- 동일 컨텍스트(스트리머+시간대+카테고리) 3시간 캐싱
- 캐시 히트율 측정

**가설 3**: 백그라운드 워커로 처리 지연 50% 이상 단축 가능
- 이벤트 큐 기반 비동기 처리
- 처리 시간 측정

### 실험 설계

#### 실험 1: 감지 알고리즘 개선 (A/B 테스트)

**대조군 (기존)**:
- 단일 임계값: 1.5배 증가
- 고정 최소 증가량: 1000명
- 모든 카테고리 동일 기준

**실험군 (개선)**:
- 다중 베이스라인:
  - 단기: 직전 60분 중앙값 (MEDIAN)
  - 장기: 7일 전 동일 시간대 평균 또는 전날 동일 시간대 평균
- 동적 임계값:
  - Major 카테고리 (상위 12개): 1.5배
  - 일반 카테고리: 1.7배
- 동적 최소 증가량: `max(1500, 기준선 * 0.3)`
- CANDIDATE 시스템: SPIKE와 CANDIDATE 구분

**측정 지표**:
- Precision: 급등으로 감지된 것 중 실제 급등 비율
- Recall: 실제 급등 중 감지된 비율
- False Positive Rate
- 일일 감지 건수

**실험 기간**: 2주 (2024년 12월)

#### 실험 2: 캐싱 시스템 도입

**설계**:
- Redis 캐시 키: `spike:{platform}:{entity}:{streamer}:{title_hash}:{time_bucket}`
- TTL: 3시간
- 캐시 히트 시 전체 분석 스킵

**측정 지표**:
- 캐시 히트율 (%)
- OpenAI API 호출 횟수 (전/후)
- 비용 절감액 ($)

**실험 기간**: 1주 (캐시 적재 후)

#### 실험 3: 백그라운드 워커 도입

**설계**:
- Postgres 기반 이벤트 큐 (analysis_status: PENDING)
- Agent Worker가 5초마다 폴링
- FOR UPDATE SKIP LOCKED로 동시성 제어

**측정 지표**:
- 평균 처리 시간 (이벤트 생성 → 분석 완료)
- 동시 처리 가능 이벤트 수
- 큐 대기 시간

**실험 기간**: 1주

---

## 3️⃣ 개선 실행

### 개선 1: 감지 알고리즘 V3

**구현 내용**:

```python
# 다중 베이스라인 계산
short_term = MEDIAN(viewers) WHERE ts BETWEEN now-60m AND now
seasonal_7d = AVG(viewers) WHERE ts BETWEEN now-170h AND now-166h
seasonal_24h = AVG(viewers) WHERE ts BETWEEN now-26h AND now-22h

# 동적 임계값
is_major = category IN top_12_by_baseline
growth_threshold = 1.5 if is_major else 1.7
min_delta = max(1500, seasonal_base * 0.3)

# 다중 조건 검증
if (current >= short_term * growth_threshold AND
    current >= seasonal_base * 1.2 AND
    delta >= min_delta):
    signal_level = "SPIKE"
elif (growth_ratio >= 1.2 AND delta >= 500):
    signal_level = "CANDIDATE"  # 후보 등록
```

**주요 개선점**:
- 중앙값 사용으로 이상치 영향 감소
- 계절성 고려 (주간/일간 패턴)
- 카테고리 규모별 차등 적용
- CANDIDATE로 False Negative 감소

### 개선 2: Redis 캐싱 시스템

**구현 내용**:

```python
# 캐시 키 생성
cache_key = f"spike:{platform}:{entity}:{streamer}:{title_hash}:{time_bucket}"

# 캐시 조회 (LangGraph 워크플로우 중)
if cache_hit:
    return cached_result  # 전체 분석 스킵
else:
    # AI 분석 수행
    result = analyze_with_ai(...)
    redis.setex(cache_key, 3*3600, result)  # 3시간 저장
```

**워크플로우**:
```
Watcher → Cache Lookup → [Hit: 종료 / Miss: Search → Analyst → Editor] → Cache Save
```

### 개선 3: Agent Worker 시스템

**구현 내용**:

```python
# 이벤트 큐에서 PENDING 조회 (동시성 제어)
SELECT event_id, ... FROM signal_events
WHERE analysis_status = 'PENDING'
ORDER BY created_at ASC
LIMIT 3
FOR UPDATE SKIP LOCKED

# 분석 수행
result = agent_app.invoke(inputs)

# 상태 업데이트
UPDATE signal_events SET analysis_status = 'DONE', ... WHERE event_id = ?
```

---

## 4️⃣ 결과 측정

### 결과 1: 감지 정확도 개선

| 지표 | 개선 전 | 개선 후 | 개선율 |
|------|---------|---------|--------|
| **일일 감지 건수** | 50-60건 | 15-20건 | -65% |
| **False Positive Rate** | ~70% | ~25% | -64% |
| **Precision** | 30% | 75% | +150% |
| **Recall** | 60% | 85% | +42% |
| **주요 급등 놓침** | 주간 3-5건 | 주간 0-1건 | -80% |

**인사이트**:
- 다중 베이스라인으로 계절성/시간대 패턴 반영 성공
- Major/일반 카테고리 구분으로 적응형 임계값 효과 확인
- CANDIDATE 시스템으로 실제 급등 놓침 대폭 감소

### 결과 2: 비용 절감

| 지표 | 개선 전 | 개선 후 | 개선율 |
|------|---------|---------|--------|
| **일일 OpenAI API 호출** | 50-60회 | 12-18회 | -70% |
| **일일 API 비용** | $15-20 | $4-6 | -70% |
| **월간 비용** | $450-600 | $120-180 | -70% |
| **캐시 히트율** | 0% | 72% | - |

**인사이트**:
- 동일 시간대/스트리머 중복 분석이 주요 원인이었음
- 3시간 TTL이 적절한 균형점 (너무 짧으면 효과 없음, 너무 길면 오래된 정보)
- 월 $300+ 절감으로 ROI 확보

### 결과 3: 처리 속도 개선

| 지표 | 개선 전 | 개선 후 | 개선율 |
|------|---------|---------|--------|
| **평균 처리 시간** | 5-10분 | 2-3분 | -60% |
| **최대 대기 시간** | 15분+ | 5분 | -67% |
| **동시 처리 가능** | 1건 | 3건 | +200% |

**인사이트**:
- 큐 기반 비동기 처리로 병목 해소
- FOR UPDATE SKIP LOCKED로 동시성 확보
- 실시간 대응 가능성 향상

---

## 5️⃣ 학습 및 개선점

### 성공 요인
1. **데이터 기반 의사결정**: 실제 운영 데이터로 문제 정의
2. **점진적 개선**: 한 번에 모든 것을 바꾸지 않고 단계별 실험
3. **측정 가능한 지표**: 정량적 지표로 효과 검증

### 개선할 점
1. **더 긴 실험 기간**: 계절성 변화 고려해 최소 1개월 이상 관찰 필요
2. **사용자 피드백**: False Positive/Negative에 대한 사용자 피드백 수집 체계화
3. **자동화된 모니터링**: 지표 추적 대시보드 구축

### 다음 단계
- 머신러닝 기반 임계값 자동 조정 (카테고리별 학습)
- 실시간 스트리밍 분석 (배치 → 스트리밍)
- 다중 플랫폼 확장 (트위치, 유튜브 등)

---

## 💡 그로스 데이터 엔지니어로서의 관점

이 경험을 통해 배운 것:

1. **문제 정의의 중요성**: 정량적 데이터로 문제를 명확히 정의해야 효과적인 해결책 도출 가능
2. **실험 설계**: 가설 설정 → 측정 지표 정의 → A/B 테스트로 과학적 검증
3. **비용 최적화**: 단순 기능 추가가 아닌 효율성 개선으로 비즈니스 가치 창출
4. **지속적 개선**: 한 번의 개선으로 끝나지 않고, 데이터를 관찰하며 지속적으로 최적화

이러한 경험을 페이타랩의 그로스 데이터 엔지니어로서 사용자 성장과 비즈니스 성과 개선에 활용하고 싶습니다.

---

**프로젝트 기간**: 2024년 10월 - 현재  
**역할**: 풀스택 개발 + 데이터 엔지니어링  
**기술 스택**: Python, FastAPI, DuckDB, Postgres, Redis, LangGraph, OpenAI API
